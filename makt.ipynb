{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from torch_geometric.data import Data\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "read_col = ['studentId', 'skill', 'problemId', 'startTime', 'correct', 'original', 'attemptCount']\n",
    "target = 'correct'\n",
    "df = pd.read_csv('jxy/KT/NoteBook/ADM2017/assisment_2017_raw.csv', low_memory=False, encoding=\"ISO-8859-1\")[read_col]\n",
    "print('original df length is %d' % len(df))\n",
    "\n",
    "\n",
    "df = df[df['original'].isin([1])]\n",
    "print('After removing scaffolding problems, records number %d' % len(df))\n",
    "\n",
    "df.sort_values('startTime', inplace=True)\n",
    "\n",
    "min_inter_num = 3\n",
    "users = df.groupby(['studentId'], as_index=True)\n",
    "delete_users = []\n",
    "for u in users:\n",
    "    if len(u[1]) < min_inter_num:\n",
    "        delete_users.append(u[0])\n",
    "\n",
    "print('deleted user number based min-inters %d' % len(delete_users))\n",
    "df = df[~df['studentId'].isin(delete_users)]\n",
    "df = df[[ 'studentId', 'skill', 'problemId', 'correct']]\n",
    "print('After deleting some users, records number %d' % len(df))\n",
    "\n",
    "\n",
    "problems_list = df['problemId'].drop_duplicates().tolist()\n",
    "skills_list = df['skill'].drop_duplicates().tolist()\n",
    "print(len(problems_list))\n",
    "print(len(skills_list))\n",
    "\n",
    "problems_dict = {i:problems_list[i] for i in range(0,len(problems_list))}\n",
    "skills_dict = {i:skills_list[i] for i in range(0,len(skills_list))}\n",
    "problems_re_dict = {problems_list[i]:i for i in range(0,len(problems_list))}\n",
    "skills_re_dict = {skills_list[i]:i for i in range(0,len(skills_list))}\n",
    "\n",
    "df['skill_cat'] = df['skill'].apply(lambda r: skills_re_dict[r])\n",
    "df['problem_cat'] = df['problemId'].apply(lambda r: problems_re_dict[r])\n",
    "\n",
    "skill_problem = df[['skill_cat', 'problem_cat']].groupby(['skill_cat'], as_index=True).apply(lambda r: np.array(list(set(r['problem_cat'].values))))\n",
    "skill_prob_dict = {}\n",
    "for skill_prob in skill_problem.index:\n",
    "    skill_prob_dict[skill_prob] = skill_problem[skill_prob]\n",
    "\n",
    "\n",
    "user_sequence = df[['studentId', 'correct', 'skill_cat', 'problem_cat']].groupby(['studentId']).apply(\n",
    "                lambda r: (r['skill_cat'].values, r['problem_cat'].values, r['correct'].values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "WINDOW = 50\n",
    "\n",
    "def co_acc_skills(user_skill, matrix_agg, matrix_cnt, skill_dict):\n",
    "    count = 0\n",
    "    agg = 0\n",
    "    for user in tqdm(user_skill.index):\n",
    "        skills = user_skill[user][0]\n",
    "        correct = user_skill[user][2]\n",
    "\n",
    "        for i in range(0,len(skills)-1):\n",
    "            for j in range(i+1, min(i+1+WINDOW, len(skills))):\n",
    "                matrix_cnt[skills[i]][skills[j]] += 1\n",
    "                matrix_agg[skills[i]][skills[j]] += correct[i] * correct[j]\n",
    "\n",
    "    return matrix_agg, matrix_cnt\n",
    "\n",
    "skill_mats = []\n",
    "print('processing skill co-currence')\n",
    "\n",
    "skills = skills_re_dict.keys()\n",
    "mat_length = len(skills)\n",
    "\n",
    "print(mat_length)\n",
    "skill_dict = {}\n",
    "skill_key = []\n",
    "\n",
    "matrix_agg = np.zeros((mat_length,mat_length))\n",
    "matrix_cnt = np.zeros((mat_length,mat_length))\n",
    "\n",
    "agg, cnt = co_acc_skills(user_sequence, matrix_agg, matrix_cnt, skills_re_dict)\n",
    "print(agg)\n",
    "print(cnt)\n",
    "res = agg / (cnt + 1e-8)\n",
    "print(res)\n",
    "#\n",
    "joblib.dump(res, 'c2c_para.pkl.zip')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dimensionK = 64\n",
    "mat = (res.transpose(1, 0) + res) / 2\n",
    "\n",
    "class MDPreTrain(nn.Module):\n",
    "    def __init__(self, a_nums, k):\n",
    "        super(MDPreTrain, self).__init__()\n",
    "        self.embed_a = torch.nn.Embedding(a_nums, k)\n",
    "\n",
    "    def forward(self, a):\n",
    "        a_vector = self.embed_a(a)\n",
    "        return torch.matmul(a_vector,a_vector.T)\n",
    "\n",
    "    def getemb(self, a):\n",
    "        return self.embed_a(a).detach().data.cpu().numpy()\n",
    "\n",
    "a = torch.tensor(np.array([_ for _ in range(0,mat.shape[0])]))\n",
    "\n",
    "ajaMat = torch.tensor(mat).float()\n",
    "md = MDPreTrain(mat.shape[0], dimensionK)\n",
    "\n",
    "optimizer = torch.optim.Adam(md.parameters(), lr=1e-2)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(0,10001)):\n",
    "    prediction = md(a)\n",
    "    loss = loss_func(prediction, ajaMat)\n",
    "    if loss.item() < 1e-3:\n",
    "        print('loss小到可以提前停止了')\n",
    "        break\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print('epoch:{}, loss:{}'.format(epoch, loss.item()))\n",
    "\n",
    "skill_emb = {}\n",
    "emb_res = md.getemb(a)\n",
    "joblib.dump(emb_res, 'emb_c2c.pkl.zip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "WINDOW = 50\n",
    "\n",
    "def co_acc_problems(user_skill, matrix_agg, matrix_cnt, skill_dict):\n",
    "    for user in tqdm(user_skill.index):\n",
    "        problems = user_skill[user][1]\n",
    "        correct = user_skill[user][2]\n",
    "        for i in range(0,len(problems)-1):\n",
    "            for j in range(i+1, min(i+1+WINDOW, len(problems))):\n",
    "                matrix_cnt[problems[i]][problems[j]] += 1\n",
    "                matrix_agg[problems[i]][problems[j]] += correct[i] * correct[j]\n",
    "    return matrix_agg, matrix_cnt\n",
    "\n",
    "\n",
    "print('processing problem co-currence')\n",
    "mat_length = len(problems_list)\n",
    "\n",
    "matrix_agg = np.zeros((mat_length,mat_length))\n",
    "matrix_cnt = np.zeros((mat_length,mat_length))\n",
    "\n",
    "\n",
    "agg, cnt = co_acc_problems(user_sequence, matrix_agg, matrix_cnt, problems_re_dict)\n",
    "print(agg)\n",
    "print(cnt)\n",
    "res = agg / (cnt + 1e-8)\n",
    "print(res)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mat = (res + res.T) / 2\n",
    "\n",
    "dimensionK = 64\n",
    "mat_length = mat.shape[0]\n",
    "\n",
    "class MDPreTrain(nn.Module):\n",
    "    def __init__(self, a_nums, k):\n",
    "        super(MDPreTrain, self).__init__()\n",
    "        self.embed_a = torch.nn.Embedding(a_nums, k)\n",
    "\n",
    "    def forward(self, a):\n",
    "        a_vector = self.embed_a(a)\n",
    "        return torch.matmul(a_vector,a_vector.T)\n",
    "\n",
    "    def getemb(self, a):\n",
    "        return self.embed_a(a).detach().data.cpu().numpy()\n",
    "\n",
    "a = torch.tensor(np.array([_ for _ in range(0,mat_length)])).cuda(0)\n",
    "\n",
    "ajaMat = torch.tensor(mat).float().cuda(0)\n",
    "md = MDPreTrain(mat_length, dimensionK).cuda(0)\n",
    "\n",
    "optimizer = torch.optim.Adam(md.parameters(), lr=1e-2)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(0,5001)):\n",
    "    prediction = md(a)\n",
    "    loss = loss_func(prediction, ajaMat)\n",
    "    if loss.item() < 1e-2:\n",
    "        print('loss小到可以提前停止了')\n",
    "        break\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print('epoch:{}, loss:{}'.format(epoch, loss.item()))\n",
    "\n",
    "skill_emb = {}\n",
    "emb_res = md.getemb(a)\n",
    "joblib.dump(emb_res, 'emb_e2e.pkl.zip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "problem_emb = {}\n",
    "emb_res = joblib.load('emb_e2e.pkl.zip')\n",
    "for i in range(0,len(emb_res)):\n",
    "    problem_emb[i] = emb_res[i].tolist()\n",
    "print(len(problem_emb))\n",
    "\n",
    "skill_emb = {}\n",
    "emb_res = joblib.load('emb_c2c.pkl.zip')\n",
    "for i in range(0,len(emb_res)):\n",
    "    skill_emb[i] = emb_res[i].tolist()\n",
    "print(len(skill_emb))\n",
    "\n",
    "df['skill_emb'] = df['skill_cat'].apply(lambda r: skill_emb[r])\n",
    "df['problem_emb'] = df['problem_cat'].apply(lambda r: problem_emb[r])\n",
    "\n",
    "new_user_sequence = df[['studentId', 'skill_cat', 'problem_cat', 'correct', 'skill_emb', 'problem_emb']].groupby(['studentId']).apply(\n",
    "                lambda r: (r['skill_cat'].values, r['problem_cat'].values, r['correct'].values, r['skill_emb'].values, r['problem_emb'].values))\n",
    "user_sequence = new_user_sequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_val_group_c = user_sequence.sample(frac=0.8, random_state=14)\n",
    "test_group_c = user_sequence[~user_sequence.index.isin(train_val_group_c.index)]\n",
    "train_group_c = train_val_group_c.sample(frac=0.75, random_state=14)\n",
    "val_group_c = train_val_group_c[~train_val_group_c.index.isin(train_group_c.index)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, group, min_samples=3, max_seq=100, cold_start=10):\n",
    "        '''需要过滤seq<3 并且>max_seq的进行折叠'''\n",
    "        self.max_seq = max_seq\n",
    "        self.samples = {}\n",
    "        self.user_ids = []\n",
    "        for user_id in group.index:\n",
    "            sids, pids, labels, s_emb, p_emb = group[user_id]\n",
    "\n",
    "            if len(labels) > self.max_seq:  # Fold\n",
    "                total_questions = len(labels)\n",
    "                initial = total_questions % self.max_seq\n",
    "                for seq in range(total_questions // self.max_seq):\n",
    "                    self.user_ids.append(f\"{user_id}_{seq}\")\n",
    "                    start = seq * self.max_seq\n",
    "                    end = start + self.max_seq\n",
    "                    self.samples[f\"{user_id}_{seq}\"] = (sids[start:end], pids[start:end], labels[start:end],\n",
    "                                                        s_emb[start:end], p_emb[start:end])\n",
    "                if initial >= min_samples:\n",
    "                    seq = total_questions // self.max_seq\n",
    "                    start = seq * self.max_seq\n",
    "                    end = start + initial\n",
    "                    self.user_ids.append(f\"{user_id}_{seq}\")\n",
    "                    self.samples[f\"{user_id}_{seq}\"] = (sids[start:end], pids[start:end], labels[start:end],\n",
    "                                                        s_emb[start:end], p_emb[start:end])\n",
    "            else:\n",
    "                user_id = str(user_id)\n",
    "                self.user_ids.append(user_id)\n",
    "                self.samples[user_id] = (sids, pids, labels, s_emb, p_emb)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_ids[index]\n",
    "        sids, pids, labels, s_embs, p_embs = self.samples[user_id]\n",
    "        seq_len = len(labels)\n",
    "        tmp_y = self.init_sequence(labels)\n",
    "        tmp_sc = self.init_sequence(sids)\n",
    "        tmp_pc = self.init_sequence(pids)\n",
    "\n",
    "        mask = np.concatenate((np.ones(seq_len - 1, dtype=bool), np.zeros(self.max_seq - seq_len, dtype=bool)))\n",
    "        tmp_s_embs = np.zeros((self.max_seq, len(s_embs[0])),dtype=float)\n",
    "        tmp_p_embs = np.zeros((self.max_seq, len(p_embs[0])),dtype=float)\n",
    "        for i in range(0,seq_len):\n",
    "            tmp_s_embs[i][:] = s_embs[i][:]\n",
    "        for i in range(0,seq_len):\n",
    "            tmp_p_embs[i][:] = p_embs[i][:]\n",
    "\n",
    "        next_y = tmp_y[1:]\n",
    "        next_p = tmp_pc[1:]\n",
    "        next_s = tmp_sc[1:]\n",
    "        now_y = tmp_y[:-1]\n",
    "        now_p = tmp_pc[:-1]\n",
    "        now_s = tmp_sc[:-1]\n",
    "\n",
    "        now_s_emb = tmp_s_embs[:-1]\n",
    "        next_s_emb = tmp_s_embs[1:]\n",
    "        now_p_emb = tmp_p_embs[:-1]\n",
    "        next_p_emb = tmp_p_embs[1:]\n",
    "\n",
    "        # return now_s, next_s, now_y, next_y, now_p, next_p, mask\n",
    "        return now_s_emb, next_s_emb, now_y, next_y, now_p_emb, next_p_emb, mask\n",
    "\n",
    "    def init_sequence(self, target, dtype_=int):\n",
    "        seq_len = len(target)\n",
    "        tmp = np.zeros(self.max_seq, dtype=dtype_)\n",
    "        tmp[:seq_len] = target\n",
    "        return tmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, s_emb_size, p_emb_size, s_emb_dim, p_emb_dim, kernel_dim, kernel_num,\n",
    "                 output_dim=1, seq_len = 99, s_total=111, p_total=15911, device=0):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.s_total = s_total\n",
    "        self.p_total = p_total\n",
    "\n",
    "        self.bond_dim = kernel_num * kernel_dim\n",
    "        self.kernel_indim = (p_emb_dim + s_emb_dim) * 2\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.kernel_num = kernel_num\n",
    "        self.head = 8\n",
    "\n",
    "        self.query_fc = nn.Linear((p_emb_dim + s_emb_dim), kernel_dim)\n",
    "        self.key_fc = nn.Linear(self.kernel_indim, kernel_dim)\n",
    "        self.head_dim = int(self.kernel_indim / 8)\n",
    "\n",
    "        self.head_out = int(self.kernel_dim / 8)\n",
    "\n",
    "        self.value_fc = nn.ModuleList([nn.Linear(in_features=self.head_dim, out_features=self.head_out, bias=True) for x in\n",
    "                                  range(self.head)])\n",
    "\n",
    "        self.kernel_fc_indim = s_emb_dim + p_emb_dim + kernel_num * kernel_dim\n",
    "        self.kernel_fc = nn.Linear(self.kernel_fc_indim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, s_now, s_next, p_now, p_next, labels):\n",
    "        batch_size = s_now.size(0)\n",
    "        seq_len = s_now.size(1)\n",
    "        input_concat = torch.cat([s_now, p_now], dim=-1).to(torch.float)\n",
    "        next_concat = torch.cat([s_next, p_next], dim=-1).to(torch.float)\n",
    "\n",
    "\n",
    "        query = self.query_fc(next_concat)\n",
    "\n",
    "        input_concat = self.emb_extend(input_concat,labels).to(torch.float32)\n",
    "        key = self.key_fc(input_concat)\n",
    "\n",
    "\n",
    "        score = torch.einsum('lik,ljk->lij', query, key)\n",
    "        k_select = []\n",
    "        for i in range(0,self.kernel_num):\n",
    "            tmp = torch.tensor(np.concatenate((np.zeros(self.kernel_num - i - 1),np.arange(0,seq_len - self.kernel_num +i + 1))), dtype=torch.int64).repeat(batch_size, 1).unsqueeze(-1).cuda(self.device)\n",
    "            k_select.append(tmp)\n",
    "\n",
    "\n",
    "        for i in range(0,self.kernel_num):\n",
    "            tmp = torch.gather(score,-1,k_select[i])\n",
    "            tmp[:,0:self.kernel_num - i - 1,:] = -1e10\n",
    "            k_select[i] = tmp\n",
    "\n",
    "        score = torch.cat(k_select, dim=-1)\n",
    "        score = F.softmax(score, dim =-1)\n",
    "\n",
    "        score = score.unsqueeze(-1).repeat(1,1,1,kernel_dim).reshape(batch_size,seq_len,self.bond_dim)\n",
    "        # input_concat = self.emb_extend(input_concat,labels).to(torch.float32)\n",
    "        zeros = torch.zeros_like(input_concat)\n",
    "\n",
    "        k_select=[]\n",
    "        for i in range(0,self.kernel_num):\n",
    "            tmp = torch.cat([zeros[:,0:self.kernel_num - i - 1,:], input_concat[:,:seq_len - self.kernel_num + i + 1,:]], dim=1)\n",
    "            tmp_list = []\n",
    "\n",
    "            for j in range(0, self.head):\n",
    "                head_in = tmp[:,:,j*self.head_dim:(j+1)*self.head_dim]\n",
    "                tmp_list.append(self.value_fc[j](head_in))\n",
    "            tmp = torch.concat(tmp_list,dim=-1)\n",
    "            k_select.append(tmp)\n",
    "\n",
    "        con_kernel = torch.cat(k_select, dim=-1)\n",
    "        # 所以最后，是sum pooling 还是concat\n",
    "        con_kernel = con_kernel * score\n",
    "\n",
    "        con_kernel = torch.tanh(con_kernel)\n",
    "        out = torch.cat([con_kernel, next_concat],dim = -1).to(torch.float)\n",
    "\n",
    "        return self.kernel_fc(out).squeeze(-1)\n",
    "\n",
    "\n",
    "    def emb_extend(self, item_inputs, label_inputs):\n",
    "        dim = item_inputs.shape[-1]\n",
    "        label_inputs = label_inputs.unsqueeze(-1).float()\n",
    "        inputs = torch.cat([item_inputs, item_inputs], dim=-1)\n",
    "        inputs[..., :dim] *= label_inputs\n",
    "        inputs[..., dim:] *= 1 - label_inputs\n",
    "        return inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process(eval, data_loader, model, optim, num, device):\n",
    "    epoch_loss = 0\n",
    "    prediction = []\n",
    "    true = []\n",
    "    binary = []\n",
    "    for data in  (data_loader):\n",
    "        input_s = data[0].cuda(device)\n",
    "        next_s = data[1].cuda(device)\n",
    "        label = data[2].cuda(device)\n",
    "        y = data[3].cuda(device)\n",
    "        input_p = data[4].cuda(device)\n",
    "        next_p = data[5].cuda(device)\n",
    "        mask = data[6].cuda(device)\n",
    "\n",
    "        batch_size = mask.shape[0]\n",
    "\n",
    "        if eval == 'train':\n",
    "            model.train()\n",
    "            optim.zero_grad()\n",
    "\n",
    "            output = model(input_s, next_s, input_p, next_p, label)\n",
    "            # return\n",
    "            logits = torch.masked_select(output,mask)\n",
    "\n",
    "            tensor_label = torch.masked_select(y,mask)\n",
    "            loss_gate = nn.BCEWithLogitsLoss()  #\n",
    "\n",
    "            tensor_label = tensor_label.to(torch.float)\n",
    "            loss = loss_gate(logits, tensor_label)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 20)\n",
    "            optim.step()\n",
    "\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "            prediction.extend(torch.sigmoid(logits).detach().cpu().numpy())\n",
    "            true.extend(tensor_label.cpu().numpy())\n",
    "\n",
    "            binary.extend((torch.sigmoid(logits).detach().cpu().numpy() >= 0.5))\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                output = model(input_s, next_s, input_p, next_p, label)\n",
    "                logits = torch.masked_select(output,mask)\n",
    "                tensor_label = torch.masked_select(y,mask)\n",
    "\n",
    "                tensor_label = tensor_label.to(torch.float)\n",
    "                prediction.extend(torch.sigmoid(logits).detach().cpu().numpy())\n",
    "                true.extend(tensor_label.cpu().numpy())\n",
    "\n",
    "                binary.extend((torch.sigmoid(logits).detach().cpu().numpy() >= 0.5))\n",
    "\n",
    "    return roc_auc_score(true,prediction), accuracy_score(true,binary)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num = 86\n",
    "\n",
    "learning_rate = .1\n",
    "timy_learning_rate = 1e-3\n",
    "epsilon = .1\n",
    "grad_threshold = 20\n",
    "model_dropout = .6\n",
    "epoch = 1000\n",
    "epoch_test = 1\n",
    "batch_size = 32\n",
    "sequence_size = 100\n",
    "sequence_threshold = 3\n",
    "cold_start = 100\n",
    "\n",
    "heads = 8\n",
    "embed_dimension = 64\n",
    "\n",
    "S_CAT_NUM = 86\n",
    "P_CAT_NUM = 1183\n",
    "S_EMBEDDING_SIZE = S_CAT_NUM\n",
    "P_EMBEDDING_SIZE = P_CAT_NUM\n",
    "\n",
    "HIDDEN_DIM = 64\n",
    "HIDDEN_LAYER = 1\n",
    "S_EMBEDDING_DIM = 64\n",
    "P_EMBEDDING_DIM = 64\n",
    "kernel_num = 16\n",
    "kernel_dim = 64\n",
    "\n",
    "DEVICE = 0\n",
    "\n",
    "train_dataset = MyDataset(train_group_c, max_seq=sequence_size, cold_start=cold_start)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataset = MyDataset(test_group_c, max_seq=sequence_size, cold_start=cold_start)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "model = BaseModel(S_EMBEDDING_SIZE, P_EMBEDDING_SIZE, S_EMBEDDING_DIM , P_EMBEDDING_DIM, kernel_dim, kernel_num,\n",
    "                  seq_len=sequence_size-1, s_total=S_CAT_NUM, p_total=P_CAT_NUM, device=DEVICE).cuda(DEVICE)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate, eps=epsilon)\n",
    "\n",
    "count_epoch_for_test = 0\n",
    "max_auc = 0\n",
    "max_acc = 0\n",
    "for i in range(epoch):\n",
    "    count_epoch_for_test += 1\n",
    "    process(eval='train', data_loader = train_dataloader, num=num, model=model, optim=optim, device=DEVICE)\n",
    "    # break\n",
    "    if count_epoch_for_test == epoch_test:\n",
    "        auc, acc = process(eval='test', data_loader = valid_dataloader, num = num, model=model, optim=optim, device=DEVICE)\n",
    "        max_auc = max(max_auc, auc)\n",
    "        max_acc = max(max_acc, acc)\n",
    "        print(\"epoch - {}/{} auc - {:.5f} acc - {:5f} max - {:.5f}/ {:.5f}\".format(i+1, epoch, auc, acc, max_auc, max_acc))\n",
    "        count_epoch_for_test = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}