{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import scipy.sparse as sp\n",
    "\n",
    "WINDOW = 60 * 60\n",
    "c2c_emb_file = '2017_CL_c2c.pkl.zip'\n",
    "e2e_emb_file = '2017_CL_e2e.pkl.zip'\n",
    "model_temp_file = 'model_temp1.pkl'\n",
    "\n",
    "DEVICE = 0\n",
    "\n",
    "dimensionK = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "read_col = ['studentId', 'skill', 'problemId', 'startTime', 'correct', 'original', 'attemptCount']\n",
    "target = 'correct'\n",
    "df = pd.read_csv('jxy/KT/NoteBook/ADM2017/assisment_2017_raw.csv', low_memory=False, encoding=\"ISO-8859-1\")[read_col]\n",
    "print('original df length is %d' % len(df))\n",
    "\n",
    "\n",
    "df = df[df['original'].isin([1])]\n",
    "print('After removing scaffolding problems, records number %d' % len(df))\n",
    "\n",
    "df.sort_values('startTime', inplace=True)\n",
    "\n",
    "min_inter_num = 3\n",
    "users = df.groupby(['studentId'], as_index=True)\n",
    "delete_users = []\n",
    "for u in users:\n",
    "    if len(u[1]) < min_inter_num:\n",
    "        delete_users.append(u[0])\n",
    "\n",
    "print('deleted user number based min-inters %d' % len(delete_users))\n",
    "df = df[~df['studentId'].isin(delete_users)]\n",
    "df = df[[ 'studentId', 'skill', 'problemId', 'correct', 'startTime']]\n",
    "print('After deleting some users, records number %d' % len(df))\n",
    "\n",
    "\n",
    "problems_list = df['problemId'].drop_duplicates().tolist()\n",
    "skills_list = df['skill'].drop_duplicates().tolist()\n",
    "print(len(problems_list))\n",
    "print(len(skills_list))\n",
    "\n",
    "problems_dict = {i:problems_list[i] for i in range(0,len(problems_list))}\n",
    "skills_dict = {i:skills_list[i] for i in range(0,len(skills_list))}\n",
    "problems_re_dict = {problems_list[i]:i for i in range(0,len(problems_list))}\n",
    "skills_re_dict = {skills_list[i]:i for i in range(0,len(skills_list))}\n",
    "\n",
    "df['skill_cat'] = df['skill'].apply(lambda r: skills_re_dict[r])\n",
    "df['problem_cat'] = df['problemId'].apply(lambda r: problems_re_dict[r])\n",
    "\n",
    "skill_problem = df[['skill_cat', 'problem_cat']].groupby(['skill_cat'], as_index=True).apply(lambda r: np.array(list(set(r['problem_cat'].values))))\n",
    "skill_prob_dict = {}\n",
    "for skill_prob in skill_problem.index:\n",
    "    skill_prob_dict[skill_prob] = skill_problem[skill_prob] # .tolist()\n",
    "\n",
    "\n",
    "user_sequence = df[['studentId', 'correct', 'skill_cat', 'problem_cat', 'startTime']].groupby(['studentId']).apply(\n",
    "                lambda r: (r['skill_cat'].values, r['problem_cat'].values, r['correct'].values, r['startTime'].values))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def co_acc_skills(user_skill, matrix_agg, matrix_cnt, skill_dict):\n",
    "    for user in tqdm(user_skill.index):\n",
    "        skills = user_skill[user][0]\n",
    "        correct = user_skill[user][2]\n",
    "        tsp = user_sequence[user][3]\n",
    "        for i in range(0,len(skills)-1):\n",
    "            for j in range(i+1, len(skills)):\n",
    "                if tsp[j] - tsp[i] > WINDOW:\n",
    "                    break\n",
    "                matrix_cnt[skills[i]][skills[j]] += 1\n",
    "                matrix_agg[skills[i]][skills[j]] += correct[i] * correct[j]\n",
    "\n",
    "    return matrix_agg, matrix_cnt\n",
    "\n",
    "skill_mats = []\n",
    "print('processing skill co-currence')\n",
    "\n",
    "skills = skills_re_dict.keys()\n",
    "mat_length = len(skills)\n",
    "\n",
    "print(mat_length)\n",
    "skill_dict = {}\n",
    "skill_key = []\n",
    "\n",
    "matrix_agg = np.zeros((mat_length,mat_length))\n",
    "matrix_cnt = np.zeros((mat_length,mat_length))\n",
    "\n",
    "agg, cnt = co_acc_skills(user_sequence, matrix_agg, matrix_cnt, skills_re_dict)\n",
    "\n",
    "res = agg / (cnt + 1e-8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mat = (res.transpose(1, 0) + res) / 2\n",
    "\n",
    "class MDPreTrain(nn.Module):\n",
    "    def __init__(self, a_nums, k):\n",
    "        super(MDPreTrain, self).__init__()\n",
    "        self.embed_a = torch.nn.Embedding(a_nums, k)\n",
    "\n",
    "    def forward(self, a):\n",
    "        a_vector = self.embed_a(a)\n",
    "        return torch.matmul(a_vector,a_vector.T)\n",
    "\n",
    "    def getemb(self, a):\n",
    "        return self.embed_a(a).detach().data.cpu().numpy()\n",
    "\n",
    "a = torch.tensor(np.array([_ for _ in range(0,mat.shape[0])]))\n",
    "\n",
    "ajaMat = torch.tensor(mat).float()\n",
    "md = MDPreTrain(mat.shape[0], dimensionK)\n",
    "\n",
    "optimizer = torch.optim.Adam(md.parameters(), lr=1e-2)\n",
    "# 优化函数\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# 损失函数\n",
    "\n",
    "for epoch in tqdm(range(0,10001)):\n",
    "    prediction = md(a)\n",
    "    loss = loss_func(prediction, ajaMat)\n",
    "    if loss.item() < 1e-3:\n",
    "        print('loss小到可以提前停止了 {}'.format(loss.item()))\n",
    "        break\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print('epoch:{}, loss:{}'.format(epoch, loss.item()))\n",
    "\n",
    "skill_emb = {}\n",
    "emb_res = md.getemb(a)\n",
    "\n",
    "print('loading in file:'+c2c_emb_file)\n",
    "joblib.dump(emb_res, c2c_emb_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def co_acc_problems(user_skill, matrix_agg, matrix_cnt, skill_dict):\n",
    "    for user in tqdm(user_skill.index):\n",
    "        problems = user_skill[user][1]\n",
    "        correct = user_skill[user][2]\n",
    "        tsp = user_skill[user][3]\n",
    "        for i in range(0,len(problems)-1):\n",
    "            for j in range(i+1, len(problems)):\n",
    "                if tsp[j] - tsp[i] > WINDOW:\n",
    "                    break\n",
    "                matrix_cnt[problems[i]][problems[j]] += 1\n",
    "                matrix_agg[problems[i]][problems[j]] += correct[i] * correct[j]\n",
    "    return matrix_agg, matrix_cnt\n",
    "\n",
    "\n",
    "print('processing problem co-currence')\n",
    "mat_length = len(problems_list)\n",
    "\n",
    "matrix_agg = np.zeros((mat_length,mat_length))\n",
    "matrix_cnt = np.zeros((mat_length,mat_length))\n",
    "\n",
    "agg, cnt = co_acc_problems(user_sequence, matrix_agg, matrix_cnt, problems_re_dict)\n",
    "res = agg / (cnt + 1e-8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_list = []\n",
    "for skill in skill_prob_dict.keys():\n",
    "    prob_list = skill_prob_dict[skill]\n",
    "    new_res = np.zeros((prob_list.shape[0],prob_list.shape[0]))\n",
    "    for i in range(0,prob_list.shape[0]):\n",
    "        for j in range(0,prob_list.shape[0]):\n",
    "            new_res[i][j] = res[prob_list[i]][prob_list[j]]\n",
    "            if i == j:  continue\n",
    "            new_res[j][i] = res[prob_list[j]][prob_list[i]]\n",
    "    res_list.append(new_res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_all_nodes_attributes_e(i,concept_length,total_length):\n",
    "    concept_attrs = np.zeros((total_length,concept_length), int)\n",
    "    concept_attrs[:,i] = 1\n",
    "    node_attrs = np.zeros((total_length, total_length), int)\n",
    "    np.fill_diagonal(node_attrs, 1)\n",
    "\n",
    "    node_attrs = np.concatenate((concept_attrs,node_attrs),axis=-1)\n",
    "    return node_attrs\n",
    "\n",
    "def get_nodes_weights_e(sub_mat):\n",
    "    weights_org = sub_mat\n",
    "    weights_org_t = weights_org.transpose()\n",
    "    weights_add = (weights_org + weights_org_t)/2\n",
    "    np.fill_diagonal(weights_add, 0)\n",
    "\n",
    "    neg_org = np.where(weights_add == 0, 1, 0)\n",
    "    np.fill_diagonal(neg_org, 0)\n",
    "\n",
    "    if np.count_nonzero(weights_add) == 0:\n",
    "        threshold = 0\n",
    "    else:\n",
    "        threshold = np.sum(weights_add) / np.count_nonzero(weights_add)\n",
    "    weights_add  = np.where(weights_add >= threshold, weights_add, 0)\n",
    "\n",
    "    edges_org = sp.coo_matrix(weights_add)\n",
    "    edges_neg = sp.coo_matrix(neg_org)\n",
    "    return edges_org, weights_add, edges_neg\n",
    "\n",
    "def normalize_adj(adj, self_loop=True):\n",
    "    if self_loop:\n",
    "        np.fill_diagonal(adj, 1)\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "def e2edataset(mat):\n",
    "    graph_list = []\n",
    "    adj_list = []\n",
    "    neg_edge_list = []\n",
    "    attr_length = 0\n",
    "    concept_length = len(mat)\n",
    "    for sub_mat in mat:\n",
    "        attr_length = max(attr_length, len(sub_mat))\n",
    "\n",
    "    for i in range(0,len(mat)):\n",
    "        sub_mat = mat[i]\n",
    "        node_attrs = get_all_nodes_attributes_e(i,concept_length,attr_length)\n",
    "        edges_org, adj, edges_neg = get_nodes_weights_e(sub_mat)\n",
    "        adj = normalize_adj(adj)\n",
    "\n",
    "        row = torch.tensor(edges_org.row)\n",
    "        col = torch.tensor(edges_org.col)\n",
    "        edge_index = torch.stack((row,col)).long()\n",
    "        edge_attr = torch.tensor(edges_org.data).float()\n",
    "\n",
    "        row = torch.tensor(edges_neg.row)\n",
    "        col = torch.tensor(edges_neg.col)\n",
    "        neg_edge_index = torch.stack((row,col)).long()\n",
    "\n",
    "        x = node_attrs[[n for n in range(0,sub_mat.shape[0])]]\n",
    "        x = torch.tensor(x).float()\n",
    "\n",
    "        sub_graph = Data(x = x, edge_index = edge_index, edge_attr = edge_attr)\n",
    "        graph_list.append(sub_graph)\n",
    "        adj_list.append(adj)\n",
    "        neg_edge_list.append(neg_edge_index)\n",
    "    return graph_list, adj_list, neg_edge_list\n",
    "\n",
    "print(\"\\nGenerate C2C with 0 threshold...\")\n",
    "Egraph_list, adj_list, neg_edge_list = e2edataset(res_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_ft, out_ft, bias=True):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.fc = nn.Linear(in_ft, out_ft, bias=False)\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(out_ft))\n",
    "        self.bias.data.fill_(0.0)\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "    def forward(self, feat, adj):\n",
    "        feat = self.fc(feat)\n",
    "        out = torch.mm(adj, feat)\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels: int, hidden_channels, out_channels: int):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.GCN1 = GCNLayer(in_channels, hidden_channels)\n",
    "        self.GCN2 = GCNLayer(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h1 = self.GCN1(x, adj)\n",
    "        h1 = torch.relu(h1)\n",
    "        h2 = self.GCN2(h1, adj)\n",
    "\n",
    "        final_sum_pooling  = torch.sum(h2,dim=0)\n",
    "        con_sum_pooling = torch.sum(torch.concat([h1,h2],dim=-1),dim=0)\n",
    "        return con_sum_pooling, final_sum_pooling\n",
    "\n",
    "    def emb_encode(self, x, adj):\n",
    "        h1 = self.GCN1(x, adj)\n",
    "        h1 = torch.relu(h1)\n",
    "        h2 = self.GCN2(h1, adj)\n",
    "        return h2\n",
    "\n",
    "class GRACE(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,  num_proj_hidden: int, tau: float = 0.5):\n",
    "        super(GRACE, self).__init__()\n",
    "        self.encoder = Encoder(in_channels,out_channels,out_channels)\n",
    "        self.tau: float = tau\n",
    "\n",
    "        self.num_proj_hidden = num_proj_hidden\n",
    "        self.num_hidden = out_channels\n",
    "\n",
    "        self.proj_head = nn.Sequential(nn.Linear(out_channels, num_proj_hidden),nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(num_proj_hidden, num_proj_hidden),nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(num_proj_hidden, 10))\n",
    "\n",
    "    def forward(self, attr, adj) -> torch.Tensor:\n",
    "        c,f = self.encoder(attr, adj)\n",
    "        return self.proj_head(f)\n",
    "\n",
    "    def loss(self, x, x_aug):\n",
    "        batch_size, _ = x.size()\n",
    "        x_abs = x.norm(dim=1)\n",
    "        x_aug_abs = x_aug.norm(dim=1)\n",
    "        sim_matrix = torch.einsum('ik,jk->ij', x, x_aug) / torch.einsum('i,j->ij', x_abs, x_aug_abs)\n",
    "        sim_matrix = torch.exp(sim_matrix / self.tau)\n",
    "        pos_sim = sim_matrix[range(batch_size), range(batch_size)]\n",
    "        loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n",
    "        loss = - torch.log(loss).mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def emb_encoder(self, attr, adj) -> torch.Tensor:\n",
    "        x = self.encoder.emb_encode(attr, adj)\n",
    "        return x\n",
    "\n",
    "\n",
    "def gen_ran_output(attr, adj, model, vice_model):\n",
    "    for (adv_name,adv_param), (name,param) in zip(vice_model.named_parameters(), model.named_parameters()):\n",
    "        if name.split('.')[0] == 'proj_head' or name.split('.')[0] == 'proj_head2':   # 两个模型是一样的，所以参数是一样的\n",
    "            adv_param.data = param.data\n",
    "        else:\n",
    "            adv_param.data = param.data + 1.0 * torch.normal(0,torch.ones_like(param.data)*param.data.std()).cuda(DEVICE)\n",
    "\n",
    "    return vice_model(attr, adj)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GCA_NUM_EPOCHS = 10001\n",
    "C_NUM = 86\n",
    "P_NUM = 1183\n",
    "in_channes = C_NUM + 429\n",
    "out_channels = dimensionK\n",
    "hidden_dim = dimensionK\n",
    "lr =.01\n",
    "proj_hidden = dimensionK\n",
    "\n",
    "def Egae_encode(graph, neg_edge,C_mat,emb_save_dir):\n",
    "    vice_model = GRACE(in_channes,out_channels,proj_hidden).cuda(DEVICE)\n",
    "    grace_model = GRACE(in_channes,out_channels,proj_hidden).cuda(DEVICE)\n",
    "    optimizer = torch.optim.Adam(grace_model.parameters(), lr=lr)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    target_Mat = torch.tensor(C_mat).to(torch.float32).cuda(DEVICE)\n",
    "    loss_min = 100000\n",
    "    epoch_min = 0\n",
    "    print('begin')\n",
    "    for epoch in tqdm(range(1, GCA_NUM_EPOCHS + 1)):\n",
    "        epoch_loss = 0\n",
    "        raw_proj_rep = []\n",
    "        ptb_proj_rep = []\n",
    "        for i in range(0,len(graph)):\n",
    "            grace_model.train()\n",
    "            vice_model.train\n",
    "            optimizer.zero_grad()\n",
    "            data = graph[i]\n",
    "            data = data.cuda(DEVICE)\n",
    "            adj = adj_list[i]\n",
    "            adj = torch.tensor(adj.todense(), dtype=torch.float32).cuda(DEVICE)\n",
    "            subg_r1 = gen_ran_output(data.x,adj, grace_model, vice_model)\n",
    "            subg_r2 = grace_model(data.x, adj)\n",
    "            raw_proj_rep.append(subg_r2.unsqueeze(0))\n",
    "            ptb_proj_rep.append(subg_r1.unsqueeze(0))\n",
    "\n",
    "        raw_proj_rep = torch.concat(raw_proj_rep,dim=0)\n",
    "        ptb_proj_rep = torch.concat(ptb_proj_rep,dim=0)\n",
    "\n",
    "        recon = torch.matmul(raw_proj_rep,raw_proj_rep.transpose(1,0))\n",
    "        loss1 = loss_func(recon, target_Mat)\n",
    "        loss2 = grace_model.loss(raw_proj_rep, ptb_proj_rep)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if epoch_loss < loss_min:\n",
    "            loss_min = epoch_loss\n",
    "            torch.save(grace_model.state_dict(), model_temp_file)\n",
    "            epoch_min = epoch\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch={:03d}, loss={:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "\n",
    "    print('(Train) | Epoch={:03d}, loss={:.4f}'.format(epoch_min, loss_min))\n",
    "    grace_model.load_state_dict(torch.load(model_temp_file))\n",
    "    grace_model.eval()\n",
    "    n2n_emb = torch.zeros(P_NUM, out_channels)\n",
    "    countP = torch.zeros(P_NUM)\n",
    "    for i in range(0,len(graph)):\n",
    "        prob_list = skill_prob_dict[i]\n",
    "        data = graph[i]\n",
    "        data = data.cuda(DEVICE)\n",
    "        adj = adj_list[i]\n",
    "        adj = torch.tensor(adj.todense(), dtype=torch.float32).cuda(DEVICE)\n",
    "        z = grace_model.emb_encoder(data.x, adj).cpu().detach()\n",
    "        for node in range(z.shape[0]):\n",
    "            n2n_emb[prob_list[node]] += z[node]\n",
    "            countP[prob_list[node]] += 1\n",
    "\n",
    "    for i in range(0,P_NUM):\n",
    "        if countP[i] >1:\n",
    "            n2n_emb[i] = n2n_emb[i] / countP[i]\n",
    "\n",
    "    n2n_emb = n2n_emb.cpu().detach()\n",
    "    joblib.dump(n2n_emb, emb_save_dir)\n",
    "\n",
    "\n",
    "Egae_encode(Egraph_list, neg_edge_list , mat, emb_save_dir=e2e_emb_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}